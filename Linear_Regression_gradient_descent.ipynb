{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "\n##### Learn more about Gradient Descent :\n - [machinelearningmastery.com](https://machinelearningmastery.com/gradient-descent-for-machine-learning/)\n - [Siraj Raval YouTube Video](https://www.youtube.com/watch?v=XdM6ER7zTLk&t=85s)\n - [spin.atomicobject.com](https://spin.atomicobject.com/2014/06/24/gradient-descent-linear-regression/)\n "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from numpy import * ",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#read the data file\npoints = genfromtxt('https://raw.githubusercontent.com/llSourcell/linear_regression_live/master/data.csv',delimiter=',')\n\n#print the first 5 records to check the data\npoints[:5,:]",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "array([[32.50234527, 31.70700585],\n       [53.42680403, 68.77759598],\n       [61.53035803, 62.5623823 ],\n       [47.47563963, 71.54663223],\n       [59.81320787, 87.23092513]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"Total records in the data file : {}\".format(len(points)))\nprint(\"What kind of Numpy Array : {} \".format(points.shape))",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Total records in the data file : 100\nWhat kind of Numpy Array : (100, 2) \n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "##### In the following functions we will be calculating the following\n - MSE (Mean Squared Error)\n - Partial derivatives for m, b\n \nThe formulas for the cost function, derivatives etc can be found [here](https://spin.atomicobject.com/2014/06/24/gradient-descent-linear-regression/)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# MSE (Mean Squared Error)\ndef compute_error(b, m, points):\n    error = 0\n    for i in range(len(points)):\n        x = points[i, 0]    # firt column from array\n        y = points[i, 1]    # second column from array\n        error += (y - (m*x + b)) ** 2\n        return error / float(len(points))",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def gradient_step(current_b, current_m, points, learning_rate):\n    b_gradient = 0\n    m_gradient = 0\n    N = float(len(points))\n    \n    for i in range(0, len(points)):\n        x = points[i, 0]\n        y = points[i, 1]\n        b_gradient += -(2/N) * (y - ((current_m * x) + current_b))\n        m_gradient += -(2/N) * x * (y - ((current_m * x) + current_b))\n    \n    new_b = current_b - (learning_rate * b_gradient)\n    new_m = current_m - (learning_rate * m_gradient)\n    \n    return [new_b, new_m]",
      "execution_count": 30,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def gradient_descent(points, learning_rate, starting_m, starting_b, num_of_iterations):\n    b = starting_b\n    m = starting_m    \n    for i in range(num_of_iterations):\n        b, m = gradient_step(b, m, array(points),learning_rate)\n    \n    return [b,m]",
      "execution_count": 35,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# lets define the hyer parameters\n# remember the formula y = mx = b\ndef main_run():\n    learning_rate = 0.0001\n    initial_m = 0\n    initial_b = 0\n    num_of_iterations = 1000\n    [b, m] = gradient_descent(points, learning_rate, initial_m, initial_b, num_of_iterations)\n    print(\"b : {} , m : {}\".format(b, m))",
      "execution_count": 36,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "main_run()",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": "b : 0.08893651993741346 , m : 1.4777440851894448\n",
          "name": "stdout"
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}